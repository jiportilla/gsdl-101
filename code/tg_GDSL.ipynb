{"cells": [{"metadata": {}, "id": "faaaf0a6", "cell_type": "markdown", "source": "# Graph Data Science Exammple"}, {"metadata": {}, "id": "earlier-product", "cell_type": "markdown", "source": "### Introduction to pyTigerGraph\n\npyTigerGraph is the Python API for TigerGraph. It can be used to query and update data in a TigerGraph database. Full documentation is available https://github.com/pyTigerGraph/pyTigerGraph\n\n"}, {"metadata": {}, "id": "absolute-launch", "cell_type": "markdown", "source": "See example at https://github.com/parkererickson/pytg-demo/blob/main/eda.ipynb"}, {"metadata": {}, "id": "0952f8eb", "cell_type": "code", "source": "!pip install pyTigerGraph", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Collecting pyTigerGraph\n  Downloading pyTigerGraph-0.0.9.9.2-py3-none-any.whl (22 kB)\nCollecting pyTigerDriver\n  Downloading pyTigerDriver-1.0.14-py3-none-any.whl (8.7 kB)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyTigerGraph) (1.3.4)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyTigerGraph) (2.26.0)\nCollecting validators\n  Downloading validators-0.19.0.tar.gz (30 kB)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->pyTigerGraph) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->pyTigerGraph) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->pyTigerGraph) (1.20.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->pyTigerGraph) (1.15.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->pyTigerGraph) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->pyTigerGraph) (1.26.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->pyTigerGraph) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->pyTigerGraph) (2.0.4)\nRequirement already satisfied: decorator>=3.4.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from validators->pyTigerGraph) (5.1.0)\nBuilding wheels for collected packages: validators\n  Building wheel for validators (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for validators: filename=validators-0.19.0-py3-none-any.whl size=19552 sha256=379fe7a480865b43aa3c574dcda5741d601eebb83ab07e37c0777d85da1dac9b\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/63/96/60/01b2d5e1cb69cb88e19141a8e39e2992454ba62dbb72c849c8\nSuccessfully built validators\nInstalling collected packages: validators, pyTigerDriver, pyTigerGraph\nSuccessfully installed pyTigerDriver-1.0.14 pyTigerGraph-0.0.9.9.2 validators-0.19.0\n", "name": "stdout"}]}, {"metadata": {}, "id": "61f0c762", "cell_type": "markdown", "source": "### Enter your server & password info"}, {"metadata": {}, "id": "b927dc25", "cell_type": "code", "source": "import getpass\n\nserver = 'https://2022v2.i.tgcloud.io'\npassword = getpass.getpass()", "execution_count": 2, "outputs": [{"output_type": "stream", "name": "stdout", "text": "\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"}]}, {"metadata": {}, "id": "36c863c0", "cell_type": "markdown", "source": "### Setup a pyTG connnection to the server"}, {"metadata": {}, "id": "ignored-astronomy", "cell_type": "markdown", "source": "Creating a Connection\nHere, we will create a connection to a TigerGraph database. There are many different parameters that can be used to connect based upon the specific instance, but we will use the defaults:"}, {"metadata": {}, "id": "bc221593", "cell_type": "code", "source": "import pyTigerGraph as tg \n\nconn = tg.TigerGraphConnection(\n    host=server, \n    graphname='social', \n    password=password)", "execution_count": 3, "outputs": []}, {"metadata": {}, "id": "2a7fbe3d", "cell_type": "code", "source": "print(conn.gsql('ls', options=[]))", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "---- Global vertices, edges, and all graphs\nVertex Types:\n- VERTEX blog(PRIMARY_ID link STRING, title STRING, id INT, link STRING, date STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n- VERTEX label(PRIMARY_ID category STRING, category STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\nEdge Types:\n- DIRECTED EDGE has_a(FROM blog, TO label, score DOUBLE)\n\nGraphs:\n- Graph ontology(blog:v, label:v, has_a:e)\nJobs:\n\n\nJSON API version: v2\nSyntax version: v2\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Next, import blogs data table as pandas dataframe", "id": "ded6da17"}, {"metadata": {}, "id": "6f7ee76b", "cell_type": "code", "source": "import pandas as pd\n\n#blogs_df = pd.read_csv(\"ibm-blogs.csv\")\n#print(\"\\nNumber of rows in ibm-blogs file: \", blogs_df.shape[0])\n#blogs_df.head()", "execution_count": 5, "outputs": []}, {"metadata": {}, "id": "fitted-comfort", "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_d77c4db6ce1d438e92a1f00e7f2d5d2d = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='hDekfN2FWkKS_xY6ChfWhFXk4iptKdhTP50fnLoIltjt',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbody = client_d77c4db6ce1d438e92a1f00e7f2d5d2d.get_object(Bucket='graphai-donotdelete-pr-4nvni6nug5azgz',Key='ibm-blogs.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\nblogs_df = pd.read_csv(body)\nblogs_df.head()\n", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "     id                     title  \\\n0  1001         Cloud at the Edge   \n1  1002    Rounding out the Edges   \n2  1003  Architecting at the Edge   \n3  1004        DevOps at the Edge   \n4  1005      Policies at the Edge   \n\n                                                link      date  \n0   https://www.ibm.com/cloud/blog/cloud-at-the-edge   2/26/19  \n1  https://www.ibm.com/cloud/blog/rounding-out-th...    5/7/19  \n2  https://www.ibm.com/cloud/blog/architecting-at...  10/21/19  \n3  https://www.ibm.com/cloud/blog/devops-at-the-edge   12/3/19  \n4  https://www.ibm.com/cloud/blog/policies-at-the...   1/22/20  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>link</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1001</td>\n      <td>Cloud at the Edge</td>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>2/26/19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002</td>\n      <td>Rounding out the Edges</td>\n      <td>https://www.ibm.com/cloud/blog/rounding-out-th...</td>\n      <td>5/7/19</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1003</td>\n      <td>Architecting at the Edge</td>\n      <td>https://www.ibm.com/cloud/blog/architecting-at...</td>\n      <td>10/21/19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1004</td>\n      <td>DevOps at the Edge</td>\n      <td>https://www.ibm.com/cloud/blog/devops-at-the-edge</td>\n      <td>12/3/19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1005</td>\n      <td>Policies at the Edge</td>\n      <td>https://www.ibm.com/cloud/blog/policies-at-the...</td>\n      <td>1/22/20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "id": "divine-study", "cell_type": "code", "source": "\nbody = client_d77c4db6ce1d438e92a1f00e7f2d5d2d.get_object(Bucket='graphai-donotdelete-pr-4nvni6nug5azgz',Key='final-categories.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ncategories_df = pd.read_csv(body)\ncategories_df.head()\n", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "                                                link  \\\n0   https://www.ibm.com/cloud/blog/cloud-at-the-edge   \n1   https://www.ibm.com/cloud/blog/cloud-at-the-edge   \n2   https://www.ibm.com/cloud/blog/cloud-at-the-edge   \n3  https://www.ibm.com/cloud/blog/rounding-out-th...   \n4  https://www.ibm.com/cloud/blog/rounding-out-th...   \n\n                                            category     score  \n0                          /technology and computing  0.869217  \n1      /technology and computing/internet technology  0.823215  \n2  /technology and computing/networking/network m...  0.808410  \n3                 /technology and computing/hardware  0.834985  \n4        /technology and computing/operating systems  0.786255  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>link</th>\n      <th>category</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>/technology and computing</td>\n      <td>0.869217</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>/technology and computing/internet technology</td>\n      <td>0.823215</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>/technology and computing/networking/network m...</td>\n      <td>0.808410</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.ibm.com/cloud/blog/rounding-out-th...</td>\n      <td>/technology and computing/hardware</td>\n      <td>0.834985</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.ibm.com/cloud/blog/rounding-out-th...</td>\n      <td>/technology and computing/operating systems</td>\n      <td>0.786255</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "id": "4e4439a9", "cell_type": "code", "source": "def create_tpl(itemOne, itemTwo, itemThree):\n    \"\"\"\n    Creates a triple series with item1,item2, item3 as input\n    Arguments:\n        item1, item2, item3 strings\n    Returns:\n        A triple series\n    \"\"\"\n    tpl = []\n    tpl.append(itemOne)\n    tpl.append(itemTwo)\n    tpl.append(itemThree)\n    return tpl", "execution_count": 8, "outputs": []}, {"metadata": {}, "id": "52d2f75a", "cell_type": "code", "source": "def get_unique(column):\n    \"\"\"\n    Get unique elements from a Pandas DF column\n    Arguments:\n        column: a DF column\n    Returns:\n        A node list with sorted, \n        unique elements of the DF column\n    \"\"\"\n    nodes = ()\n    nodes = sorted( list(column.unique() ) )\n    return nodes ", "execution_count": 9, "outputs": []}, {"metadata": {}, "id": "009e0f90", "cell_type": "code", "source": "rows = []\nfor _, row in categories_df.iterrows():\n    cats = row['category'].split('/')\n    cats = list(filter(None, cats))\n    \n    for c in cats:\n        tpl = create_tpl(row['link'], c, row['score'])\n        rows.append(tpl)\n\ncat_df = pd.DataFrame(rows)\ncat_df.rename(columns={0: 'link', 1: 'category', 2: 'score'}, inplace=True)\nprint(\"\\nNumber of rows in cat_df : \", cat_df.shape[0])\ncat_df.head()", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "\nNumber of rows in cat_df :  155\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "                                               link                  category  \\\n0  https://www.ibm.com/cloud/blog/cloud-at-the-edge  technology and computing   \n1  https://www.ibm.com/cloud/blog/cloud-at-the-edge  technology and computing   \n2  https://www.ibm.com/cloud/blog/cloud-at-the-edge       internet technology   \n3  https://www.ibm.com/cloud/blog/cloud-at-the-edge  technology and computing   \n4  https://www.ibm.com/cloud/blog/cloud-at-the-edge                networking   \n\n      score  \n0  0.869217  \n1  0.823215  \n2  0.823215  \n3  0.808410  \n4  0.808410  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>link</th>\n      <th>category</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>technology and computing</td>\n      <td>0.869217</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>technology and computing</td>\n      <td>0.823215</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>internet technology</td>\n      <td>0.823215</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>technology and computing</td>\n      <td>0.808410</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>networking</td>\n      <td>0.808410</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "id": "6deeb7ca", "cell_type": "code", "source": "#Get the category with the highest score for each blog\n\n\nblog_category1 = cat_df.drop_duplicates(\nsubset = ['link','category'], keep = 'first').reset_index(drop = True)\n\nblog_category1", "execution_count": 11, "outputs": [{"output_type": "execute_result", "execution_count": 11, "data": {"text/plain": "                                                  link  \\\n0     https://www.ibm.com/cloud/blog/cloud-at-the-edge   \n1     https://www.ibm.com/cloud/blog/cloud-at-the-edge   \n2     https://www.ibm.com/cloud/blog/cloud-at-the-edge   \n3     https://www.ibm.com/cloud/blog/cloud-at-the-edge   \n4    https://www.ibm.com/cloud/blog/rounding-out-th...   \n..                                                 ...   \n104  https://www.ibm.com/cloud/blog/optical-charact...   \n105  https://www.ibm.com/cloud/blog/optical-charact...   \n106  https://www.ibm.com/cloud/blog/optical-charact...   \n107  https://www.ibm.com/cloud/blog/optical-charact...   \n108  https://www.ibm.com/cloud/blog/optical-charact...   \n\n                              category     score  \n0             technology and computing  0.869217  \n1                  internet technology  0.823215  \n2                           networking  0.808410  \n3    network monitoring and management  0.808410  \n4             technology and computing  0.834985  \n..                                 ...       ...  \n104           technology and computing  0.978824  \n105                           hardware  0.978824  \n106                           computer  0.978824  \n107                           software  0.931648  \n108                computer components  0.915361  \n\n[109 rows x 3 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>link</th>\n      <th>category</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>technology and computing</td>\n      <td>0.869217</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>internet technology</td>\n      <td>0.823215</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>networking</td>\n      <td>0.808410</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.ibm.com/cloud/blog/cloud-at-the-edge</td>\n      <td>network monitoring and management</td>\n      <td>0.808410</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.ibm.com/cloud/blog/rounding-out-th...</td>\n      <td>technology and computing</td>\n      <td>0.834985</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>https://www.ibm.com/cloud/blog/optical-charact...</td>\n      <td>technology and computing</td>\n      <td>0.978824</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>https://www.ibm.com/cloud/blog/optical-charact...</td>\n      <td>hardware</td>\n      <td>0.978824</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>https://www.ibm.com/cloud/blog/optical-charact...</td>\n      <td>computer</td>\n      <td>0.978824</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>https://www.ibm.com/cloud/blog/optical-charact...</td>\n      <td>software</td>\n      <td>0.931648</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>https://www.ibm.com/cloud/blog/optical-charact...</td>\n      <td>computer components</td>\n      <td>0.915361</td>\n    </tr>\n  </tbody>\n</table>\n<p>109 rows \u00d7 3 columns</p>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "id": "magnetic-distance", "cell_type": "code", "source": "#Get a list of unique categories \n\n\ncategories_df = cat_df.drop_duplicates(\nsubset = ['category'], keep = 'first').reset_index(drop = True)\n\ncategories_df =  categories_df.drop(['link', 'score'], axis=1)", "execution_count": 12, "outputs": []}, {"metadata": {}, "id": "transparent-palestine", "cell_type": "code", "source": "print(\"\\nNumber of rows in categories_df file: \", categories_df.shape[0])\ncategories_df.head()", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "\nNumber of rows in categories_df file:  24\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "                            category\n0           technology and computing\n1                internet technology\n2                         networking\n3  network monitoring and management\n4                           hardware", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>technology and computing</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>internet technology</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>networking</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>network monitoring and management</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hardware</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "id": "ethical-anaheim", "cell_type": "code", "source": "conn = tg.TigerGraphConnection(\n    host=server, \n    graphname='ontology', \n    password=password)", "execution_count": 14, "outputs": []}, {"metadata": {}, "id": "laden-marina", "cell_type": "code", "source": "print(conn.gsql('ls', options=[]))", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "---- Graph ontology\nVertex Types:\n- VERTEX blog(PRIMARY_ID link STRING, title STRING, id INT, link STRING, date STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n- VERTEX label(PRIMARY_ID category STRING, category STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\nEdge Types:\n- DIRECTED EDGE has_a(FROM blog, TO label, score DOUBLE)\n\nGraphs:\n- Graph ontology(blog:v, label:v, has_a:e)\nJobs:\nQueries:\n\n\n\n\n", "name": "stdout"}]}, {"metadata": {}, "id": "palestinian-pitch", "cell_type": "code", "source": "secret = conn.createSecret()\nconn.getToken(secret=secret);", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "---", "id": "a5987ab0"}, {"metadata": {}, "id": "differential-survival", "cell_type": "code", "source": "conn.getVertexStats(conn.getVertexTypes())", "execution_count": 17, "outputs": [{"output_type": "execute_result", "execution_count": 17, "data": {"text/plain": "{'blog': {'id': {'MAX': 1021, 'MIN': 1001, 'AVG': 1011}}, 'label': {}}"}, "metadata": {}}]}, {"metadata": {}, "id": "saving-monte", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "unlimited-brazilian", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "silent-oklahoma", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "conventional-survey", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "id": "c29cf325", "cell_type": "code", "source": "print(conn.gsql('''\ndrop graph ontology\ndrop edge has_a\ndrop vertex blog\ndrop vertex label\n'''))\n", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "The graph ontology could not be dropped!\nSemantic Check Fails: The edge type 'has_a' could not be found.\nFailed to drop edge types: [has_a].\nSemantic Check Fails: The vertex type 'blog' could not be found.\nFailed to drop vertex types: [blog].\nSemantic Check Fails: The vertex type 'label' could not be found.\nFailed to drop vertex types: [label].\n", "name": "stdout"}]}, {"metadata": {}, "id": "6772970a", "cell_type": "code", "source": "print(conn.gsql('''\nCREATE vertex blog (PRIMARY_ID link string, title string, id int, \n                      link string, date string)\n\nCREATE vertex label (PRIMARY_ID category string, category string\n                      )\n                      \nCREATE directed edge has_a (from blog, to label, \n                                   score DOUBLE)\n                                   \nCREATE graph ontology (*)\n''', options=[]))", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "Successfully created vertex types: [blog].\nSuccessfully created vertex types: [label].\nSuccessfully created edge types: [has_a].\nThe graph ontology is created.\n", "name": "stdout"}]}, {"metadata": {}, "id": "collaborative-navigator", "cell_type": "markdown", "source": "Verifying the Connection\nWe will print out the result of a GSQL LS command to verify that we are connected to the database."}, {"metadata": {}, "id": "unlimited-islam", "cell_type": "code", "source": "print(conn.gsql(\"LS\"))", "execution_count": 21, "outputs": [{"output_type": "stream", "text": "---- Graph ontology\nVertex Types:\n- VERTEX blog(PRIMARY_ID link STRING, title STRING, id INT, link STRING, date STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n- VERTEX label(PRIMARY_ID category STRING, category STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\nEdge Types:\n- DIRECTED EDGE has_a(FROM blog, TO label, score DOUBLE)\n\nGraphs:\n- Graph ontology(blog:v, label:v, has_a:e)\nJobs:\nQueries:\n\n\n\n\n", "name": "stdout"}]}, {"metadata": {}, "id": "a1203fa9", "cell_type": "code", "source": "secret = conn.createSecret()\nconn.getToken(secret=secret);", "execution_count": 22, "outputs": []}, {"metadata": {}, "id": "33a6848c", "cell_type": "code", "source": "conn.upsertVertexDataFrame(df=blogs_df, vertexType='blog', v_id='link')", "execution_count": 23, "outputs": [{"output_type": "execute_result", "execution_count": 23, "data": {"text/plain": "21"}, "metadata": {}}]}, {"metadata": {}, "id": "offshore-ethics", "cell_type": "code", "source": "conn.upsertVertexDataFrame(df=categories_df, vertexType='label', v_id='category')", "execution_count": 24, "outputs": [{"output_type": "execute_result", "execution_count": 24, "data": {"text/plain": "24"}, "metadata": {}}]}, {"metadata": {}, "id": "fluid-portuguese", "cell_type": "code", "source": "conn.upsertEdgeDataFrame(\n    df=blog_category1,\n    sourceVertexType='blog',\n    edgeType='has_a',\n    targetVertexType='label',\n    from_id='link',\n    to_id='category',\n    attributes={'score':'score'}\n)", "execution_count": 26, "outputs": [{"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "109"}, "metadata": {}}]}, {"metadata": {}, "id": "general-wisconsin", "cell_type": "code", "source": "conn.getVertexStats(conn.getVertexTypes())", "execution_count": 27, "outputs": [{"output_type": "execute_result", "execution_count": 27, "data": {"text/plain": "{'blog': {'id': {'MAX': 1021, 'MIN': 1001, 'AVG': 1011}}, 'label': {}}"}, "metadata": {}}]}, {"metadata": {}, "id": "cellular-bradford", "cell_type": "code", "source": "conn.getEdgeStats(conn.getEdgeTypes())", "execution_count": 28, "outputs": [{"output_type": "execute_result", "execution_count": 28, "data": {"text/plain": "{'has_a': {'score': {'MAX': 0.9969, 'MIN': 0.63099, 'AVG': 0.90616}}}"}, "metadata": {}}]}, {"metadata": {}, "id": "fallen-thumbnail", "cell_type": "markdown", "source": "### Some sample queries"}, {"metadata": {}, "id": "b36a4d3e", "cell_type": "code", "source": "q = conn.gsql('select count(*) from blog')\nq", "execution_count": 29, "outputs": [{"output_type": "execute_result", "execution_count": 29, "data": {"text/plain": "'[{\\n\"count\": 21,\\n\"v_type\": \"blog\"\\n}]'"}, "metadata": {}}]}, {"metadata": {}, "id": "43f68007", "cell_type": "code", "source": "conn.gsql('select * from blog where primary_id==\"https://www.ibm.com/cloud/blog/cloud-at-the-edge\"')", "execution_count": 30, "outputs": [{"output_type": "execute_result", "execution_count": 30, "data": {"text/plain": "'[{\\n\"v_id\": \"https://www.ibm.com/cloud/blog/cloud-at-the-edge\",\\n\"attributes\": {\\n\"date\": \"2/26/19\",\\n\"link\": \"https://www.ibm.com/cloud/blog/cloud-at-the-edge\",\\n\"id\": 1001,\\n\"title\": \"Cloud at the Edge\"\\n},\\n\"v_type\": \"blog\"\\n}]'"}, "metadata": {}}]}, {"metadata": {}, "id": "false-estimate", "cell_type": "markdown", "source": "## PageRank - Centrality"}, {"metadata": {}, "id": "ae60f049", "cell_type": "code", "source": "#pr = open(\"tg_pagerank.gsql\").read()\n\npr = '''\nDROP QUERY tg_pagerank\nCREATE QUERY tg_pagerank (SET<STRING> v_type, SET<STRING> e_type,\n FLOAT max_change=0.001, INT max_iter=25, FLOAT damping=0.85, INT top_k = 100,\n BOOL print_accum = TRUE, STRING result_attr =  \"\", STRING file_path = \"\",\n BOOL display_edges = FALSE) {\n/*\n Compute the pageRank score for each vertex in the GRAPH\n In each iteration, compute a score for each vertex:\n     score = (1-damping) + damping*sum(received scores FROM its neighbors).\n The pageRank algorithm stops when either of the following is true:\n a) it reaches max_iter iterations;\n b) the max score change for any vertex compared to the last iteration <= max_change.\n v_type: vertex types to traverse          print_accum: print JSON output\n e_type: edge types to traverse            result_attr: INT attr to store results to\n max_iter; max #iterations                 file_path: file to write CSV output to\n top_k: #top scores to output              display_edges: output edges for visualization\n max_change: max allowed change between iterations to achieve convergence\n damping: importance of traversal vs. random teleport\n\n This query supports only taking in a single edge for the time being (8/13/2020).\n*/\nTYPEDEF TUPLE<VERTEX Vertex_ID, FLOAT score, FLOAT trust_score> Vertex_Score;\nHeapAccum<Vertex_Score>(top_k, score DESC) @@top_scores_heap;\nMaxAccum<FLOAT> @@max_diff = 9999;    # max score change in an iteration\nSumAccum<FLOAT> @sum_recvd_score = 0; # sum of scores each vertex receives FROM neighbors\nSumAccum<FLOAT> @sum_score = 1;           # initial score for every vertex is 1.\nSetAccum<EDGE> @@edge_set;             # list of all edges, if display is needed\nFILE f (file_path);\n\n# PageRank iterations\t\nStart = {v_type};                     # Start with all vertices of specified type(s)\nWHILE @@max_diff > max_change \n    LIMIT max_iter DO\n        @@max_diff = 0;\n    V = SELECT s\n\tFROM Start:s -(e_type:e)-> v_type:t\n\tACCUM \n            t.@sum_recvd_score += s.@sum_score/(s.outdegree(e_type)) \n\tPOST-ACCUM \n            s.@sum_score = (1.0-damping) + damping * s.@sum_recvd_score,\n\t    s.@sum_recvd_score = 0,\n\t    @@max_diff += abs(s.@sum_score - s.@sum_score');\nEND; # END WHILE loop\n\n# Output\nIF file_path != \"\" THEN\n    f.println(\"Vertex_ID\", \"PageRank\");\nEND;\nV = SELECT s \n    FROM Start:s\n    POST-ACCUM \n        IF result_attr != \"\" THEN \n            s.setAttr(result_attr, s.@sum_score) \n        END,\n   \n\tIF file_path != \"\" THEN \n            f.println(s, s.@sum_score) \n        END,\n   \n\tIF print_accum THEN \n            @@top_scores_heap += Vertex_Score(s, s.@sum_score, s.trust_score) \n        END;\n\nIF print_accum THEN\n    PRINT @@top_scores_heap;\n    IF display_edges THEN\n        PRINT Start[Start.@sum_score];\n\tStart = SELECT s\n\t        FROM Start:s -(e_type:e)-> v_type:t\n\t        ACCUM @@edge_set += e;\n        PRINT @@edge_set;\n    END;\nEND;\n}\n\nINSTALL QUERY tg_pagerank\n'''", "execution_count": 70, "outputs": []}, {"metadata": {}, "id": "981b2c1b", "cell_type": "code", "source": "print(pr)", "execution_count": 71, "outputs": [{"output_type": "stream", "text": "\nDROP QUERY tg_pagerank\nCREATE QUERY tg_pagerank (SET<STRING> v_type, SET<STRING> e_type,\n FLOAT max_change=0.001, INT max_iter=25, FLOAT damping=0.85, INT top_k = 100,\n BOOL print_accum = TRUE, STRING result_attr =  \"\", STRING file_path = \"\",\n BOOL display_edges = FALSE) {\n/*\n Compute the pageRank score for each vertex in the GRAPH\n In each iteration, compute a score for each vertex:\n     score = (1-damping) + damping*sum(received scores FROM its neighbors).\n The pageRank algorithm stops when either of the following is true:\n a) it reaches max_iter iterations;\n b) the max score change for any vertex compared to the last iteration <= max_change.\n v_type: vertex types to traverse          print_accum: print JSON output\n e_type: edge types to traverse            result_attr: INT attr to store results to\n max_iter; max #iterations                 file_path: file to write CSV output to\n top_k: #top scores to output              display_edges: output edges for visualization\n max_change: max allowed change between iterations to achieve convergence\n damping: importance of traversal vs. random teleport\n\n This query supports only taking in a single edge for the time being (8/13/2020).\n*/\nTYPEDEF TUPLE<VERTEX Vertex_ID, FLOAT score, FLOAT trust_score> Vertex_Score;\nHeapAccum<Vertex_Score>(top_k, score DESC) @@top_scores_heap;\nMaxAccum<FLOAT> @@max_diff = 9999;    # max score change in an iteration\nSumAccum<FLOAT> @sum_recvd_score = 0; # sum of scores each vertex receives FROM neighbors\nSumAccum<FLOAT> @sum_score = 1;           # initial score for every vertex is 1.\nSetAccum<EDGE> @@edge_set;             # list of all edges, if display is needed\nFILE f (file_path);\n\n# PageRank iterations\t\nStart = {v_type};                     # Start with all vertices of specified type(s)\nWHILE @@max_diff > max_change \n    LIMIT max_iter DO\n        @@max_diff = 0;\n    V = SELECT s\n\tFROM Start:s -(e_type:e)-> v_type:t\n\tACCUM \n            t.@sum_recvd_score += s.@sum_score/(s.outdegree(e_type)) \n\tPOST-ACCUM \n            s.@sum_score = (1.0-damping) + damping * s.@sum_recvd_score,\n\t    s.@sum_recvd_score = 0,\n\t    @@max_diff += abs(s.@sum_score - s.@sum_score');\nEND; # END WHILE loop\n\n# Output\nIF file_path != \"\" THEN\n    f.println(\"Vertex_ID\", \"PageRank\");\nEND;\nV = SELECT s \n    FROM Start:s\n    POST-ACCUM \n        IF result_attr != \"\" THEN \n            s.setAttr(result_attr, s.@sum_score) \n        END,\n   \n\tIF file_path != \"\" THEN \n            f.println(s, s.@sum_score) \n        END,\n   \n\tIF print_accum THEN \n            @@top_scores_heap += Vertex_Score(s, s.@sum_score, s.trust_score) \n        END;\n\nIF print_accum THEN\n    PRINT @@top_scores_heap;\n    IF display_edges THEN\n        PRINT Start[Start.@sum_score];\n\tStart = SELECT s\n\t        FROM Start:s -(e_type:e)-> v_type:t\n\t        ACCUM @@edge_set += e;\n        PRINT @@edge_set;\n    END;\nEND;\n}\n\nINSTALL QUERY tg_pagerank\n\n", "name": "stdout"}]}, {"metadata": {}, "id": "6d3e38ba", "cell_type": "code", "source": "def createParamString(vertexTypes, edgeTypes, params):\n    paramUrl = \"\"\n    for vType in vertexTypes:\n        paramUrl += (\"v_type=\"+vType+\"&\")\n    for eType in edgeTypes:\n        paramUrl += (\"e_type=\"+eType+\"&\")\n    for p in params.keys():\n        paramUrl += (p+\"=\"+str(params[p])+\"&\")\n    paramUrl = paramUrl[:-1]\n    return paramUrl", "execution_count": 72, "outputs": []}, {"metadata": {}, "id": "415daa73", "cell_type": "code", "source": "params = {\n    \"v_type\": \"blog\",\n     \"v_type\": \"label\",\n    \"e_type\": \"has_a\"\n}", "execution_count": 73, "outputs": []}, {"metadata": {}, "id": "91984d7b", "cell_type": "code", "source": "print(conn.gsql(pr))", "execution_count": 74, "outputs": [{"output_type": "stream", "text": "Semantic Check Fails: These queries could not be found anywhere: [tg_pagerank].\n\nType Check Error in query tg_pagerank (TYP-158): line 62, col 63\n's.trust_score' indicates no valid vertex type.\nPossible reasons:\n\n- The expression refers to a primary_id, which is not directly\nusable in the query body. To use primary_id, declare it as an\nattribute. E.g \"CREATE VERTEX Person (PRIMARY_ID ssn string, ssn string, age\nint)\"\n- The expression has misspelled an attribute, or a vertex name\n\nFailed to create queries: [tg_pagerank].\n", "name": "stdout"}]}, {"metadata": {}, "id": "9682494f", "cell_type": "code", "source": "params = {\n    \"top_k\":1500,\n}\n\n", "execution_count": 37, "outputs": []}, {"metadata": {}, "id": "55b2622d", "cell_type": "code", "source": "#res = conn.runInstalledQuery(\"tg_pagerank\", \n#                             params=createParamString(conn.getVertexTypes(), \n#                                conn.getEdgeTypes(), params))[0][\"@@top_scores_heap\"]\n", "execution_count": 31, "outputs": []}, {"metadata": {}, "id": "current-philippines", "cell_type": "markdown", "source": "# Louvain - Community"}, {"metadata": {}, "id": "sensitive-license", "cell_type": "code", "source": "lv = '''\nCREATE QUERY tg_louvain(SET<STRING> v_type, SET<STRING> e_type, STRING wt_attr = \"weight\", INT max_iter = 10, \n  STRING result_attr = \"cid\", STRING file_path = \"\", BOOL print_info = FALSE)  SYNTAX V1 {\n\n  /*\n  louvain community detection algorithm\n  add keyword DISTRIBUTED for cluster environment\n\n  Parameters:\n  v_type: vertex types to traverse\n  e_type: edge types to traverse\n  wt_attr: attribute name for edge weights use empty string is graph is unweighted\n  wt_attr type is hardcoded to FLOAT INT or DOUBLE can be supported by changing all `e.getAttr(wt_attr, \"FLOAT\")`\n  to `e.getAttr(wt_attr, \"INT\")` or `e.getAttr(wt_attr, \"DOUBLE\")`\n  * note: when there is a weight attribute missmatch, there may not be an explicit error message\n  all print results showing 0 data are present is an indication that there might be a weight attribute missmatch\n  \n  max_iter: maximum iteration of louvain optimization\n  result_attr: attribute name to assign community id results to; use empty string to skip\n  file_path: file path to write CSV output to; use empty string to skip\n  print_info: print louvain execution info\n  */\n\n  TYPEDEF TUPLE <FLOAT deltaQ, FLOAT weight, VERTEX cc> move;\n  SumAccum<FLOAT> @sum_ac; #sum of the degrees of all the vertices in community C of the vertex\n  ListAccum<VERTEX> @cc_list; #the community center\n  SumAccum<FLOAT> @sum_weight; # total weight incident to this vertex\n  SumAccum<FLOAT> @sum_cc_weight; # total weight incident to the cc vertex\n  MapAccum<VERTEX,SumAccum<FLOAT>> @A_map; #A[c]: sum of the edge weights for the edges in community c\n  MaxAccum<move> @max_best_move; # highest dQ, highest -Outdegree, highest cc\n  ListAccum<VERTEX> @cm_list;  #community member list\n  SumAccum<FLOAT> @@sum_m; # total edge weight\n  SumAccum<INT> @sum_outdegree;   # helper variable for outdegree calculation\n  SumAccum<INT> @@sum_cc_change;\n  MapAccum<INT, SumAccum<INT>> @@community_map;\n  MapAccum<INT, SumAccum<INT>> @@community_size_count;\n  FILE f(file_path);\n\n  // initialize\n  Start = {v_type};\n  Start = SELECT s \n          FROM Start:s -(e_type:e)- :t\n          ACCUM\n              @@sum_m += e.getAttr(wt_attr, \"FLOAT\")*0.5,\n              s.@sum_weight += e.getAttr(wt_attr, \"FLOAT\")*1.0,\n              s.@sum_cc_weight += e.getAttr(wt_attr, \"FLOAT\")*1.0,\n              s.@sum_outdegree += 1\n          // mark @cc only for vertices with more than 1 neighbors\n          // and only the marked vertices will participate in the actual louvain algorithm\n          // the unmorked vertices will be resolved by the vertex following heuristic\n          POST-ACCUM\n              IF s.@sum_outdegree > 1 THEN \n                  s.@cc_list += s \n              END;\n  IF print_info THEN\n      PRINT Start.size() AS AllVertexCount;\n  END;\n\n  // special @cc update in the first iteration\n  Start = SELECT t \n          FROM Start:s -(e_type:e)- :t\n          WHERE s.@sum_outdegree > 1 AND t.@sum_outdegree > 1\n          ACCUM\n              t.@max_best_move += move(e.getAttr(wt_attr, \"FLOAT\")*1.0 + @@sum_m*t.@sum_weight * \n              (t.@sum_weight - s.@sum_weight), -s.@sum_cc_weight, s.@cc_list.get(0))\n          POST-ACCUM\n              IF t.@max_best_move.deltaQ > 0 THEN\n                  IF -t.@max_best_move.weight < t.@sum_cc_weight THEN\n                      t.@cc_list.clear(),\n                      t.@cc_list += t.@max_best_move.cc,\n                      t.@sum_cc_weight = -t.@max_best_move.weight,\n                      @@sum_cc_change += 1\n                  ELSE\n                      IF -t.@max_best_move.weight == t.@sum_cc_weight AND getvid(t) < getvid(t.@max_best_move.cc)  THEN\n                          t.@cc_list.clear(),\n                          t.@cc_list += t.@max_best_move.cc,\n                          t.@sum_cc_weight = -t.@max_best_move.weight,\n                          @@sum_cc_change += 1\n                      END\n                  END\n              END;\n  IF print_info THEN\n      PRINT @@sum_cc_change AS InitChangeCount;\n  END;\n\n  // main loop\n  WHILE @@sum_cc_change > 0 LIMIT max_iter DO\n      // initialize for iteration\n      @@sum_cc_change = 0;\n      Start = SELECT s \n              FROM Start:s\n              WHERE s.@sum_outdegree > 1\n              POST-ACCUM\n                  s.@sum_ac = 0,\n                  s.@cm_list.clear(),\n                  s.@A_map.clear();\n\n      Start = SELECT s \n              FROM Start:s\n              ACCUM\n                  FOREACH v IN s.@cc_list DO\n                      CASE WHEN getvid(v) != -1 THEN \n                          v.@cm_list += s \n                      END\n                  END;\n\n      Start = SELECT s \n              FROM Start:s -(e_type:e)- :t\n              WHERE t.@sum_outdegree > 1\n              ACCUM \n                  s.@A_map += (t.@cc_list.get(0) -> e.getAttr(wt_attr, \"FLOAT\")*1.0);\n\n      Start = SELECT s \n              FROM Start:s\n              ACCUM\n                  FOREACH v IN s.@cc_list DO\n                      CASE WHEN getvid(v) != -1 THEN \n                          v.@sum_ac += s.@sum_weight \n                      END\n                  END;\n\n      Start = SELECT s \n              FROM Start:s\n              ACCUM\n                  FOREACH v IN s.@cm_list DO\n                      CASE WHEN getvid(v) != -1 THEN \n                          v.@sum_ac = s.@sum_ac \n                      END\n                  END;\n\n      // compute @max_dQ\n      Start = SELECT s \n              FROM Start:s -(e_type:e)- :t\n              WHERE t.@sum_outdegree > 1\n              ACCUM\n                  INT A_s = 0,\n                  IF s.@A_map.containsKey(s) THEN \n                      A_s = s.@A_map.get(s) \n                  END,\n                  s.@max_best_move += move(s.@A_map.get(t.@cc_list.get(0)) - A_s + \n                  1/@@sum_m*s.@sum_weight*(s.@sum_ac-t.@sum_ac), -t.@sum_cc_weight, t.@cc_list.get(0))\n              POST-ACCUM\n                  IF s.@max_best_move.deltaQ > 0 THEN\n                      IF -s.@max_best_move.weight < s.@sum_cc_weight THEN   // smallest best_move weight < current weight\n                          s.@cc_list.clear(),\n                          s.@cc_list += s.@max_best_move.cc,\n                          s.@sum_cc_weight = -s.@max_best_move.weight,\n                          @@sum_cc_change += 1\n                      ELSE\n                          IF -s.@max_best_move.weight == s.@sum_cc_weight AND getvid(s.@cc_list.get(0)) < getvid(s.@max_best_move.cc)  THEN\n                              s.@cc_list.clear(),\n                              s.@cc_list += s.@max_best_move.cc,\n                              s.@sum_cc_weight = -s.@max_best_move.weight,\n                              @@sum_cc_change += 1\n                          END\n                      END\n                  END;\n      IF print_info THEN\n          PRINT @@sum_cc_change AS IterChangeCount;\n      END;\n  END;\n\n  // process node with outdegree=1\n  // follow the vertex to its neighbor's community\n  // if the neighbor also have outdegree=1, mark the two vertices as one community\n  Start = {v_type};\n  Start = SELECT s \n          FROM Start:s -(e_type:e)- :t\n          WHERE s.@sum_outdegree == 1 AND t.@sum_outdegree != 1\n          ACCUM \n              s.@cc_list += t.@cc_list.get(0);\n  IF print_info THEN\n      PRINT Start.size() AS VertexFollowedToCommunity;\n  END;\n\n  Start = {v_type};\n  Start = SELECT s \n          FROM Start:s -(e_type:e)- :t\n          WHERE s.@sum_outdegree == 1 AND t.@sum_outdegree == 1\n          ACCUM\n              IF getvid(s) <= getvid(t) THEN\n                  s.@cc_list += s\n              ELSE\n                  s.@cc_list += t\n              END;\n  IF print_info THEN\n      PRINT Start.size() AS VertexFollowedToVertex;\n  END;\n\n  // process node with outdegree=0\n  // assign them to communities containing only itself\n  Start = {v_type};\n  Start = SELECT s \n          FROM Start:s\n          WHERE s.@sum_outdegree == 0\n          ACCUM \n              s.@cc_list += s;\n  IF print_info THEN\n      PRINT Start.size() AS VertexAssignedToItself;\n  END;\n\n  // save result\n  Start = {v_type};\n  Start = SELECT s \n          FROM Start:s\n          POST-ACCUM\n              IF result_attr != \"\" THEN \n                  s.setAttr(result_attr, getvid(s.@cc_list.get(0))) \n              END,\n              IF file_path != \"\" THEN \n                  f.println(s, getvid(s.@cc_list.get(0))) \n              END;\n\n  // print result satistic\n  IF print_info THEN\n      Start = SELECT s \n              FROM Start:s\n              WHERE s.@cc_list.size() > 0\n              POST-ACCUM\n                  @@community_map += (getvid(s.@cc_list.get(0)) -> 1);\n      PRINT @@community_map.size() AS FinalCommunityCount;\n  END;\n}\n\n\n'''", "execution_count": 32, "outputs": []}, {"metadata": {}, "id": "chief-springer", "cell_type": "code", "source": "print(lv)", "execution_count": 34, "outputs": [{"output_type": "stream", "text": "\nCREATE QUERY tg_louvain(SET<STRING> v_type, SET<STRING> e_type, STRING wt_attr = \"weight\", INT max_iter = 10, \n  STRING result_attr = \"cid\", STRING file_path = \"\", BOOL print_info = FALSE)  SYNTAX V1 {\n\n  /*\n  louvain community detection algorithm\n  add keyword DISTRIBUTED for cluster environment\n\n  Parameters:\n  v_type: vertex types to traverse\n  e_type: edge types to traverse\n  wt_attr: attribute name for edge weights use empty string is graph is unweighted\n  wt_attr type is hardcoded to FLOAT INT or DOUBLE can be supported by changing all `e.getAttr(wt_attr, \"FLOAT\")`\n  to `e.getAttr(wt_attr, \"INT\")` or `e.getAttr(wt_attr, \"DOUBLE\")`\n  * note: when there is a weight attribute missmatch, there may not be an explicit error message\n  all print results showing 0 data are present is an indication that there might be a weight attribute missmatch\n  \n  max_iter: maximum iteration of louvain optimization\n  result_attr: attribute name to assign community id results to; use empty string to skip\n  file_path: file path to write CSV output to; use empty string to skip\n  print_info: print louvain execution info\n  */\n\n  TYPEDEF TUPLE <FLOAT deltaQ, FLOAT weight, VERTEX cc> move;\n  SumAccum<FLOAT> @sum_ac; #sum of the degrees of all the vertices in community C of the vertex\n  ListAccum<VERTEX> @cc_list; #the community center\n  SumAccum<FLOAT> @sum_weight; # total weight incident to this vertex\n  SumAccum<FLOAT> @sum_cc_weight; # total weight incident to the cc vertex\n  MapAccum<VERTEX,SumAccum<FLOAT>> @A_map; #A[c]: sum of the edge weights for the edges in community c\n  MaxAccum<move> @max_best_move; # highest dQ, highest -Outdegree, highest cc\n  ListAccum<VERTEX> @cm_list;  #community member list\n  SumAccum<FLOAT> @@sum_m; # total edge weight\n  SumAccum<INT> @sum_outdegree;   # helper variable for outdegree calculation\n  SumAccum<INT> @@sum_cc_change;\n  MapAccum<INT, SumAccum<INT>> @@community_map;\n  MapAccum<INT, SumAccum<INT>> @@community_size_count;\n  FILE f(file_path);\n\n  // initialize\n  Start = {v_type};\n  Start = SELECT s \n          FROM Start:s -(e_type:e)- :t\n          ACCUM\n              @@sum_m += e.getAttr(wt_attr, \"FLOAT\")*0.5,\n              s.@sum_weight += e.getAttr(wt_attr, \"FLOAT\")*1.0,\n              s.@sum_cc_weight += e.getAttr(wt_attr, \"FLOAT\")*1.0,\n              s.@sum_outdegree += 1\n          // mark @cc only for vertices with more than 1 neighbors\n          // and only the marked vertices will participate in the actual louvain algorithm\n          // the unmorked vertices will be resolved by the vertex following heuristic\n          POST-ACCUM\n              IF s.@sum_outdegree > 1 THEN \n                  s.@cc_list += s \n              END;\n  IF print_info THEN\n      PRINT Start.size() AS AllVertexCount;\n  END;\n\n  // special @cc update in the first iteration\n  Start = SELECT t \n          FROM Start:s -(e_type:e)- :t\n          WHERE s.@sum_outdegree > 1 AND t.@sum_outdegree > 1\n          ACCUM\n              t.@max_best_move += move(e.getAttr(wt_attr, \"FLOAT\")*1.0 + @@sum_m*t.@sum_weight * \n              (t.@sum_weight - s.@sum_weight), -s.@sum_cc_weight, s.@cc_list.get(0))\n          POST-ACCUM\n              IF t.@max_best_move.deltaQ > 0 THEN\n                  IF -t.@max_best_move.weight < t.@sum_cc_weight THEN\n                      t.@cc_list.clear(),\n                      t.@cc_list += t.@max_best_move.cc,\n                      t.@sum_cc_weight = -t.@max_best_move.weight,\n                      @@sum_cc_change += 1\n                  ELSE\n                      IF -t.@max_best_move.weight == t.@sum_cc_weight AND getvid(t) < getvid(t.@max_best_move.cc)  THEN\n                          t.@cc_list.clear(),\n                          t.@cc_list += t.@max_best_move.cc,\n                          t.@sum_cc_weight = -t.@max_best_move.weight,\n                          @@sum_cc_change += 1\n                      END\n                  END\n              END;\n  IF print_info THEN\n      PRINT @@sum_cc_change AS InitChangeCount;\n  END;\n\n  // main loop\n  WHILE @@sum_cc_change > 0 LIMIT max_iter DO\n      // initialize for iteration\n      @@sum_cc_change = 0;\n      Start = SELECT s \n              FROM Start:s\n              WHERE s.@sum_outdegree > 1\n              POST-ACCUM\n                  s.@sum_ac = 0,\n                  s.@cm_list.clear(),\n                  s.@A_map.clear();\n\n      Start = SELECT s \n              FROM Start:s\n              ACCUM\n                  FOREACH v IN s.@cc_list DO\n                      CASE WHEN getvid(v) != -1 THEN \n                          v.@cm_list += s \n                      END\n                  END;\n\n      Start = SELECT s \n              FROM Start:s -(e_type:e)- :t\n              WHERE t.@sum_outdegree > 1\n              ACCUM \n                  s.@A_map += (t.@cc_list.get(0) -> e.getAttr(wt_attr, \"FLOAT\")*1.0);\n\n      Start = SELECT s \n              FROM Start:s\n              ACCUM\n                  FOREACH v IN s.@cc_list DO\n                      CASE WHEN getvid(v) != -1 THEN \n                          v.@sum_ac += s.@sum_weight \n                      END\n                  END;\n\n      Start = SELECT s \n              FROM Start:s\n              ACCUM\n                  FOREACH v IN s.@cm_list DO\n                      CASE WHEN getvid(v) != -1 THEN \n                          v.@sum_ac = s.@sum_ac \n                      END\n                  END;\n\n      // compute @max_dQ\n      Start = SELECT s \n              FROM Start:s -(e_type:e)- :t\n              WHERE t.@sum_outdegree > 1\n              ACCUM\n                  INT A_s = 0,\n                  IF s.@A_map.containsKey(s) THEN \n                      A_s = s.@A_map.get(s) \n                  END,\n                  s.@max_best_move += move(s.@A_map.get(t.@cc_list.get(0)) - A_s + \n                  1/@@sum_m*s.@sum_weight*(s.@sum_ac-t.@sum_ac), -t.@sum_cc_weight, t.@cc_list.get(0))\n              POST-ACCUM\n                  IF s.@max_best_move.deltaQ > 0 THEN\n                      IF -s.@max_best_move.weight < s.@sum_cc_weight THEN   // smallest best_move weight < current weight\n                          s.@cc_list.clear(),\n                          s.@cc_list += s.@max_best_move.cc,\n                          s.@sum_cc_weight = -s.@max_best_move.weight,\n                          @@sum_cc_change += 1\n                      ELSE\n                          IF -s.@max_best_move.weight == s.@sum_cc_weight AND getvid(s.@cc_list.get(0)) < getvid(s.@max_best_move.cc)  THEN\n                              s.@cc_list.clear(),\n                              s.@cc_list += s.@max_best_move.cc,\n                              s.@sum_cc_weight = -s.@max_best_move.weight,\n                              @@sum_cc_change += 1\n                          END\n                      END\n                  END;\n      IF print_info THEN\n          PRINT @@sum_cc_change AS IterChangeCount;\n      END;\n  END;\n\n  // process node with outdegree=1\n  // follow the vertex to its neighbor's community\n  // if the neighbor also have outdegree=1, mark the two vertices as one community\n  Start = {v_type};\n  Start = SELECT s \n          FROM Start:s -(e_type:e)- :t\n          WHERE s.@sum_outdegree == 1 AND t.@sum_outdegree != 1\n          ACCUM \n              s.@cc_list += t.@cc_list.get(0);\n  IF print_info THEN\n      PRINT Start.size() AS VertexFollowedToCommunity;\n  END;\n\n  Start = {v_type};\n  Start = SELECT s \n          FROM Start:s -(e_type:e)- :t\n          WHERE s.@sum_outdegree == 1 AND t.@sum_outdegree == 1\n          ACCUM\n              IF getvid(s) <= getvid(t) THEN\n                  s.@cc_list += s\n              ELSE\n                  s.@cc_list += t\n              END;\n  IF print_info THEN\n      PRINT Start.size() AS VertexFollowedToVertex;\n  END;\n\n  // process node with outdegree=0\n  // assign them to communities containing only itself\n  Start = {v_type};\n  Start = SELECT s \n          FROM Start:s\n          WHERE s.@sum_outdegree == 0\n          ACCUM \n              s.@cc_list += s;\n  IF print_info THEN\n      PRINT Start.size() AS VertexAssignedToItself;\n  END;\n\n  // save result\n  Start = {v_type};\n  Start = SELECT s \n          FROM Start:s\n          POST-ACCUM\n              IF result_attr != \"\" THEN \n                  s.setAttr(result_attr, getvid(s.@cc_list.get(0))) \n              END,\n              IF file_path != \"\" THEN \n                  f.println(s, getvid(s.@cc_list.get(0))) \n              END;\n\n  // print result satistic\n  IF print_info THEN\n      Start = SELECT s \n              FROM Start:s\n              WHERE s.@cc_list.size() > 0\n              POST-ACCUM\n                  @@community_map += (getvid(s.@cc_list.get(0)) -> 1);\n      PRINT @@community_map.size() AS FinalCommunityCount;\n  END;\n}\n\n\n\n", "name": "stdout"}]}, {"metadata": {}, "id": "lucky-missouri", "cell_type": "code", "source": "#print(conn.gsql(lv))", "execution_count": 36, "outputs": []}, {"metadata": {}, "id": "considered-discrimination", "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}